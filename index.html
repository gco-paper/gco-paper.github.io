<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation">
  <meta name="keywords" content="Flow-Matching, Manipulation, Robotics, Multi-Agent">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation</title>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SXKGE3VR46"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-SXKGE3VR46');
</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.gif">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- 
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">In Submission</a>,</span>
            <span class="author-block">
          </div>
            <p class="is-size-5 publication-authors"> Unknown University </p>
            <div class="is-size-5 publication-authors">
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="gco-supplementary" controls playsinline height="100%">
          <source src="./static/videos/gco_video_supp.mp4" 
                  type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Video summary.
      </h2>
    </div>
  </div>
</section>




<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="video-matrix">
        <div class="video-item">
          <video poster="" autoplay muted loop playsinline>
            <source src="./static/videos/empty_front_r3o2.mp4" type="video/mp4">
          </video>
          <div class="video-caption">Three robots manipulate two objects around a small obstacle.</div>
        </div>
        <div class="video-item">
          <video poster="" autoplay muted loop playsinline>
            <source src="./static/videos/slalom_front_r9o4.mp4" type="video/mp4">
          </video>
          <div class="video-caption">Long horizon manipulation in clutter, with nine robots and four objects.</div>
        </div>
        <div class="video-item">
          <video poster="" autoplay muted loop playsinline>
            <source src="./static/videos/wall_front_r5o3.mp4" type="video/mp4">
          </video>
          <div class="video-caption">Five robots manipulate three objects. Robots avoid a wall and switch objects as necessary</div>
        </div>
        <div class="video-item">
          <video poster="" autoplay muted loop playsinline>
            <source src="./static/videos/mj_slalom_small_r3o1.mp4" type="video/mp4" scale="0.5">
          </video>
          <div class="video-caption">We trained our models on data collected in MujoCo. (This video is of an older version.)</div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered video-subtitle">
        Balancing flow-matching discrete-continuous co-generation with scalable multi-robot motion planning enables flexible multi-robot manipulation.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Model Variants Comparison</h2>
      <div class="generation-videos-container">
        <div class="generation-video-item dc-contribution">
          <video autoplay muted loop playsinline>
            <source src="./static/videos/dc_iteration_000_generation_animation.mp4" type="video/mp4">
          </video>
            <div class="generation-video-caption">
              <h4 class="title is-5">GCo-DC <br>(Discrete-Continuous)</h4>
              <p>Co-generates discrete contact points and continuous manipulation trajectories.</p>
            </div>
          </div>
          <div class="generation-video-item cc-variant">
            <video autoplay muted loop playsinline>
              <source src="./static/videos/cc_iteration_000_generation_animation.mp4" type="video/mp4">
            </video>
            <div class="generation-video-caption">
              <h4 class="title is-5">GCo-CC <br>(Continuous-Continuous)</h4>
              <p>Co-generates continuous contact formations and continuous manipulation trajectories.</p>
            </div>
          </div>
          <div class="generation-video-item ct-variant">
            <video autoplay muted loop playsinline>
              <source src="./static/videos/ct_iteration_000_generation_animation.mp4" type="video/mp4">
            </video>
            <div class="generation-video-caption">
              <h4 class="title is-5">CT <br>(Continuous-Trajectory)</h4>
              <p>Generates only an unconstrained continuous trajectory. The first configuration of the trajectory is treated as the contact point.</p>
            </div>
          </div>
        </div>
        <div class="generation-footnote">
          <p><strong>Note:</strong> In these animations of GCo-DC and GCo-CC, trajectories are translated to begin at the contact points for visualization purposes. In practice, trajectories are generated with their initial configurations being the origin.</p>
          <ul>
            <li><strong>GCo-DC:</strong> Contact points are chosen from the perceived space as discrete choices over pixels.</li>
            <li><strong>GCo-CC:</strong> Contact points remain unconstrained in the continuous space.</li>
            <li><strong>CT:</strong> No explicit co-generation of contact formations.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Experimentation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Flow-Matching Co-Generation</h2>

        <div class="content has-text-justified">
          <p>
            <img src="./static/images/model_ill3.png" width="50%"
            class="model-illustration-image"
            alt="Model illustration."/>
            Our flow-matching co-generation framework addresses the fundamental challenge of jointly reasoning about contact formation and manipulation trajectories. The model takes visual observations of the environment, a robot budget, and a required transformation for the observed object, and co-generates discrete contact points alongside continuous manipulation trajectories. This dual representation ties contact planning to the perceptual space, avoiding reasoning over large continuous spaces unnecessarily, while maintaining flexibility for generating smooth manipulation trajectories.
          </p>
        </div>
      </div>
    </div>
    <!--/ Experimentation. -->

    <div class="columns is-centered">
      <!-- Manipulation Tasks. -->
      <div class="column">
        <div class="content">
          <h3 class="title is-3">Collaborative</h3>
          <img src="./static/images/closeup.png"
              class="collaborative-image"
              alt="Collaborative result."/>
          <p>
            Our approach enables collaboration between multiple robots for manipulating multiple objects. GCo handles scenarios where the number of objects is greater than the number of robots and vice versa.
          </p>
        </div>
      </div>

      <div class="column">
        <h3 class="title is-3">Long-Horizon</h3>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images/slalom_env_crop.png"
                 class="long-horizon-image"
                 alt="Long-horizon result."/>
            <p>
              The framework can handle long-horizon manipulation tasks in complex, cluttered environments. GC0 does so by learning the portions that are hard to model with flow-matching co-generation, and planning those that can be modeled well (object and robot non-interacting motions) with scalable motion planning.
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--/ Manipulation tasks. -->


  </div>
</section>


<!-- <section class="section" id="BibTeX">
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Coordinating a team of robots to reposition multiple objects in cluttered environments requires reasoning jointly about where robots should establish contact, how to manipulate objects once contact is made, and how to navigate safely and efficiently at scale. Prior approaches typically fall into two extremes--either learning the entire task or relying on privileged information and hand-designed planners--both of which struggle to handle diverse objects in long-horizon tasks. To address these challenges, we present a unified framework for collaborative multi-robot, multi-object non-prehensile manipulation that integrates flow-matching co-generation with anonymous multi-robot motion planning. Within this framework, a generative model co-generates contact formations and manipulation trajectories from visual observations, while a novel motion planner conveys robots at scale. Crucially, the same planner also supports coordination at the object level, assigning manipulated objects to larger target structures and thereby unifying robot- and object-level reasoning within a single algorithmic framework. Experiments in challenging simulated environments demonstrate that our approach outperforms baselines in both motion planning and manipulation tasks, highlighting the benefits of generative co-design and integrated planning for scaling collaborative manipulation to complex multi-agent, multi-object settings.       </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website was adapted from <a href="https://nerfies.github.io">Nerfies</a>, and is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
